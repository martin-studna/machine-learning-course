{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-1127901b-5d7e-4911-b9ef-61073241be73",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "461e5c5e",
    "execution_start": 1634729794932,
    "execution_millis": 3120,
    "deepnote_cell_type": "code"
   },
   "source": "#!/usr/bin/env python3\n# TM1: Martin Studna 55d956fd-25b4-11ec-986f-f39926f24a9c\n# TM2: Roman Ruzica  2f67b427-a885-11e7-a937-00505601122b\n# TM3: IS (id yet unknown)\n\nimport argparse\nimport lzma\nimport os\nimport pickle\nimport urllib.request\n\nimport numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures\nimport sklearn.compose\nimport sklearn.datasets\nimport sklearn.model_selection\nimport sklearn.pipeline\nimport sklearn.preprocessing\nfrom sklearn import linear_model\n\n\nclass Dataset:\n    \"\"\"Rental Dataset.\n    The dataset instances consist of the following 12 features:\n    - season (1: winter, 2: spring, 3: summer, 4: autumn)\n    - year (0: 2011, 1: 2012)\n    - month (1-12)\n    - hour (0-23)\n    - holiday (binary indicator)\n    - day of week (0: Sun, 1: Mon, ..., 6: Sat)\n    - working day (binary indicator; a day is neither weekend nor holiday)\n    - weather (1: clear, 2: mist, 3: light rain, 4: heavy rain)\n    - temperature (normalized so that -8 Celsius is 0 and 39 Celsius is 1)\n    - feeling temperature (normalized so that -16 Celsius is 0 and 50 Celsius is 1)\n    - relative humidity (0-1 range)\n    - windspeed (normalized to 0-1 range)\n    The target variable is the number of rentals in the given hour.\n    \"\"\"\n\n    def __init__(self,\n                 name=\"rental_competition.train.npz\",\n                 url=\"https://ufal.mff.cuni.cz/~straka/courses/npfl129/2122/datasets/\"):\n        if not os.path.exists(name):\n            print(\"Downloading dataset {}...\".format(name))\n            urllib.request.urlretrieve(url + name, filename=name)\n\n        # Load the dataset and return the data and targets.\n        dataset = np.load(name)\n        for key, value in dataset.items():\n            setattr(self, key, value)\n\n\nparser = argparse.ArgumentParser()\n# These arguments will be set appropriately by ReCodEx, even if you change them.\nparser.add_argument(\"--predict\", default=None, type=str,\n                    help=\"Run prediction on given data\")\nparser.add_argument(\"--recodex\", default=False,\n                    action=\"store_true\", help=\"Running in ReCodEx\")\nparser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n# For these and any other arguments you add, ReCodEx will keep your default value.\nparser.add_argument(\n    \"--model_path\", default=\"rental_competition.model\", type=str, help=\"Model path\")\n\nparser.add_argument(\"--poly_degrees\", default=2, type=int, help=\"degree of polynomial features\")\nparser.add_argument(\"--test_size\", default=0.2, type=float, help=\"relative test size\")\n\n\ndef main(args: argparse.Namespace):\n    poly = PolynomialFeatures(degree=args.poly_degrees, include_bias=False)\n    if args.predict is None:\n        # We are training a model.\n        np.random.seed(args.seed)\n        dataset = Dataset()\n\n\n\n        int_col_indices = np.where((np.mod(dataset.data, 1) != 0).sum(axis = 0) == 0)[0]\n        float_col_indices   = np.where((np.mod(dataset.data, 1) != 0).sum(axis = 0) != 0)[0]\n\n\n        col_transformer = sklearn.compose.ColumnTransformer(\n            [('encoder', sklearn.preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"), int_col_indices), (\"scaler\", sklearn.preprocessing.StandardScaler(), float_col_indices)])\n\n\n        pipe = sklearn.pipeline.Pipeline([\n            ('column_transformer', col_transformer),\n            ('polynomial_transformer', poly)\n        ])\n\n        pipe.fit(dataset.data)\n        transformed_data = pipe.transform(dataset.data)\n\n        X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n        transformed_data, dataset.target, test_size=args.test_size, random_state=args.seed)\n\n\n        # TODO: Train a model on the given dataset and store it in `model`.\n        ridge_cv_model = sklearn.linear_model.RidgeCV(alphas=np.logspace(-6, 6, 200)).fit(X_train, y_train)\n        poisson_model = sklearn.linear_model.PoissonRegressor(alpha=0.5, max_iter=100000).fit(X_train, y_train)\n       \n        print('''training_set_score\n         . \n        ''', \n        \"ridge_cv_model\", ridge_cv_model.score(X_train, y_train),\n        \"poisson_model\", poisson_model.score(X_train, y_train))\n\n        print('''training_set_rmse\n         . \n        ''', \n        \"ridge_cv_model\", sklearn.metrics.mean_squared_error(\n        ridge_cv_model.predict(X_train),y_train, squared = False),\n\n        \"poisson_model\", sklearn.metrics.mean_squared_error(\n        poisson_model.predict(X_train), y_train, squared = False),\n        )\n\n        # Serialize the model.\n\n        print('''test_set_score\n         . \n        ''', \n        \"ridge_cv_model\", ridge_cv_model.score(X_test, y_test),\n        \"poisson_model\", poisson_model.score(X_test, y_test))\n\n        print('''test_set_rmse\n         . \n        ''', \n        \"ridge_cv_model\", sklearn.metrics.mean_squared_error(\n        ridge_cv_model.predict(X_test), y_test, squared = False),\n\n        \"poisson_model\", sklearn.metrics.mean_squared_error(\n        poisson_model.predict(X_test), y_test, squared = False),\n        )\n        print(\"best ridge cv alpha\", ridge_cv_model.best_score_, ridge_cv_model.alpha_)\n\n\n        with lzma.open(f\"{args.model_path}_pipe\", \"wb\") as transform_file:\n            pickle.dump(pipe, transform_file)\n\n        with lzma.open(args.model_path, \"wb\") as model_file:\n            pickle.dump(ridge_cv_model, model_file)\n\n    else:\n        # Use the model and return test set predictions, as either a Python list or a NumPy array.\n        test = Dataset(args.predict)\n        with lzma.open(\"rental_competition.model\", \"rb\") as model_file:\n            model = pickle.load(model_file)\n\n        with lzma.open(f\"{args.model_path}_pipe\", \"rb\") as transform_file:\n            pipe = pickle.load(transform_file)\n\n        test_transformed = pipe.transform(test.data)\n        # TODO: Generate `predictions` with the test set predictions.\n\n        predictions = model.predict(test_transformed)\n\n        # rmse = sklearn.metrics.mean_squared_error(y_true, y_pred,\n        # print rmse\n        return predictions\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args([] if \"__file__\" not in globals() else None)\n    main(args)\n",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "training_set_score\n         . \n         ridge_cv_model 0.9665596165878411 poisson_model 0.9812772844943006\ntraining_set_rmse\n         . \n         ridge_cv_model 32.60118021535306 poisson_model 18.267702970508928\ntest_set_score\n         . \n         ridge_cv_model 0.8601828190392097 poisson_model 0.8835334355010949\ntest_set_rmse\n         . \n         ridge_cv_model 58.80812649480384 poisson_model 57.70483441693404\nbest ridge cv alpha -5074.89716378579 4.297004704320835\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f52cf0ae-3d63-4628-bc2e-4e8df4a581c6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "8a4d486b-8a13-48da-a4dc-6716c0817f12",
  "deepnote_execution_queue": []
 }
}
